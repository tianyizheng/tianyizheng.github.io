---
layout: post
comments: true
title:  "Journal - MLP"
date:   2018-04-011
excerpt: "Multilayer Perceptron. This is not a tutorial."
image: "/images/neuralnet.jpg"
---

##Perceptron

{: style="text-align:center"}
![Perceptron](/images/4_11/perceptron.png)

*(Source: Deep Learning and ANN, leriomaggio)*

A perceptron is the simplest form of a neural net. It has two layers: inputs and outputs. Nothing is hidden and everything feedsforward. In the picture above, w represents weights, which will be changing after each epoch. Their result will be summed and passed to a smoothing function to get the output. Here is a more in-depth look:

{: style="text-align:center"}
![SingleLayer](/images/4_11/single_layer.png)

*(Source: Python Machine Learning, S. Raschka)*

First thing you'd probably notice is that a bias unit was added to the weights and given a predefiend input. The bias unit is there to increase the flexibility of the network. In the simplest example, if all input units are 0, then if sigmoid is used for smoothing, the prediciton will always be 1, since the weights' changes won't affect the output anymore. The bias unit, along with its weight, will help nudge the neural net to the right direction. 

So here's the logic behind a single perceptron(Just realized this sound a lot like a Transformer's name). After each epoch, the weights will be updated. The amount to update is equal to the learning rate times the gradient of the objective function, which is the sum of squared errors. The direction is opposite to the direction of the gradient. In gradient descent optimization, all weights are updated simultaneously after each epoch. To get the partial derivative for each weight, take the difference between the disired label and the activation of the neuron and get the product between the difference and the respective input. The activation depends on the function, but for a perceptron using linear activation and step function smoothing, simply get the dot product between the input vector and the weights.

This is called gradient descent. Essentially you are taking the gradient of the cost function, which is the sume of squared errors, and subtract it from the weight to go to the opposite direction. The rate is limited by the learning rate, and the bias help incrase flexibility.

## Multilayer Perceptron


{: style="text-align:center"}
![MultiLayer](/images/4_11/multi_layer.png)

*(Source: Python Machine Learning, S. Raschka)*

As you can see, this network has one hidden layer. If the network has more than one hidden layer, we call it a deep ANN. Note: watch out for notations, they are a bit 'backwards'? but will make sense during the actual computing stage when we need to vectorize everything.

The forward propogation is pretty much the same. The tricky part is now the backward propogation for gradient descent. The trick here is when taking the derivative of error against weight from layer p to layer q, we can use the chain rule to find it as taking the derivative against input to layer q and then derivative of Iq to weight qp. The latter will simply become the output of layer p!. 

To put it simply, to find the change of weights needed for the activation unit qp, we need to find a delta q that is the derivate of the cost function to the input of q. For the outermost layer, the delta is simply the required value minus actual output. For the hidden layers, it reduces to the delta from the layer before it times the weight of the activation unit. 