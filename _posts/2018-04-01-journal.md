---
layout: post
comments: true
title:  "Journal - On Perception and ResNet"
date:   2018-04-01
excerpt: "Problem with synthetic data in robot perception training."
image: "/images/neuralnet.jpg"
---

### Challenges in Modern Robot Perception

During today's research on the state-of-the art advances on robot perception, I was admiring the achievements from the [RAIL](http://www.rail.gatech.edu) lab at GaTech led by Dr.Sonia Chernova. One of her Phd student's work really stood out to me. [Jonathan Balloch](http://www.cc.gatech.edu/~jballoch6/) wrote a paper last year on using a combination of realistic synthetic data and real standard training data for segmenting video frames from a robot. Several key takeaways from this paper occured to me: 

1. Scene parsing(segmenting the entire scene) is important for the future of robotics. Unlike the most popular Pascal VOC, CityScapes or NYU v2 datasets, the MIT ADE20K dataset address this issue by labeling every pixel with one of 150 class labels over twenty thousand frames.
2. Good synthetic data can help robot generate labeled samples from their own simulations, which can improve their vision systems.
2. There is a lack of large amount of realistic training data suitable for robot perception training The Rule of 10 was mentioned in the paper:

	> Canonical literature in data-driven approaches to machine learning often reiterate the “Rule of 10,” stating that for each degree of freedom that the algorithm is attempting to model there should be ten times as many training examples

3. Manual labeling is labor intensive, and dataset like NYU v2 simply cannot satisfy the need for robot perception training. Synthetic data can help. However, realistic sensor inputs from a robot can suffer from blurs, differing camera instrinsics, variable white and color balance and rapid movements. If these issues are not addressed in the training dataset, the resulting model could perform badly due to overfitting.

### Synthetic Dataset
To address this issue, this paper uses SceneNet RGB-D,which contains synthetic annotated data from video captures of 3D simulated scenes. They pretrained the data, then fine-tuned it on real sensor outputs from a Vector HRI robot that were annotated using iSeg on ADE20K labels. 

The rest of the paper talks about the experiment. The neural net model was a Pyramid Scene Parsing Network based ona a ResNet-50 using Caffe. I did some research on ResNet, with my limited understanding, here is what I learned. 

### ResNet

Kaiming He(何恺明) is an absolute beast when it comes to computer vision and deep learning. He's won several Best Paper Award in CVPR and ICCV and developed state-of-the-art ResNet, Faster-R-CNN and Mask R-CNN. ResNet was developed when he was in Microsoft. It won the ImageNet competition, beat the humans and became a prevalent architecutre for deep learning today. It stands for Residual Learning and was designed to address the problem involved with deep neural nets, specifically degradation. 

{: style="text-align:center"}
![Resnet](/images/resnet.png)

In this figure, x denotes the inputto the first layer and H(x) is the underlying mapping. F(x)represents a mapping of `H(x) - x`, where H(x) is the desired original mapping. In another word, `H(x) := F(x) + x`. As it is shown in the figure above, this formulation was realized by a feedforware neural net with "shortcut connections". It subtracts the inputs from some layers before, hence the name residual. THe idea behind it comes from the degradation problem, where adding more nonlinear layers increased the error of the output. Logically speaking, if the new layers were constructed as identity mappings, then it should not have created more errors. Therefore, the problem may lie in the solver's ability to approximate non linear layers's identity mappings. The authors want to make it easier for this approximation to happend, so they came up with the idea to give the solver reference to an identity mapping before the current layer. Thus ResNet was born.

### Random Topics Refresher

* Least Square: a type of problem for regression where we want to fit a function to the data such that the sume of squares(distance) are minimum
* Gradient Descent: the iterative method to solve a LSQ problem. Iteratively fit the function until the gradient of error becomes 0 or minimum
* Stochastic Gradient Descent: Basically uses random walks to update cost at the end of every training instance. It runs much faster on large data set
* [Single Value Decomposation](https://www.youtube.com/watch?v=P5mlg91as1c): I've originally learned this in DataVis during a lecture for Text Mining. I came upon this technique randomly today and have forgotten what it was. This video from Stanford does a good job explaining SVD. 

### End

I was really excited after reading this paper and decided to jog down what I learned from it. There is still a lot of work to be done on exploring this concept, which has the potential to become the state-of-the-art way of training robot perceptions. [Read](http://www2.ece.rochester.edu/projects/rail/ssrr2017/contributions/balloch_rss17_ssrr_ws.pdf) the original paper if you want to learn more and please let me know if I missed something exciting! 