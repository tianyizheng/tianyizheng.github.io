---
layout: post
comments: true
title:  "Journal - About Caffe and ResNet"
date:   2018-04-01
excerpt: "Getting started with Caffe and what is ResNet"
image: "/images/neuralnet.jpg"
---

### Challenges in Modern Robot Perception

During today's research on the state-of-the art advances on robot perception, I was reviewing the achievements from the RAIL lab at GaTech led by Dr.Sonia Chernova. One of her Phd student's work really stood out to me. Jonathan Balloch wrote a paper last year on using a combination of realistic synthetic data and real standard training data for segmenting video frames from a robot. Several key takeaways from this paper occured to me: 

1. Scene parsing(segmenting the entire scene) is important for the future of robotics. Unlike the most popular Pascal VOC, CityScapes or NYU v2 datasets, the MIT ADE20K dataset address this issue by labeling every pixel with one of 150 class labels over twenty thousand frames.
2. Good synthetic data can help robot generate labeled samples from their own simulations, which can improve their vision systems.
2. There is a lack of large amount of realistic training data suitable for robot perception training (going by the Rule of 10). Manual labeling is labor intensive, and dataset like NYU v2 simply cannot satisfy the need for robot perception training. Synthetic data can help. However, realistic sensor inputs from a robot can suffer from blurs, differing camera instrinsics, variable white and color balance and rapid movements. If these issues are not addressed in the training dataset, the resulting model could perform badly due to overfitting.

### Synthetic Dataset
To address this issue, this paper uses SceneNet RGB-D,which contains synthetic annotated data from video captures of 3D simulated scenes. They pretrained the data, then fine-tuned it on real sensor outputs from a Vector HRI robot that were annotated using iSeg on ADE20K labels. 

The rest of the paper talks about the experiment. The neural net model was a Pyramid Scene Parsing Network based ona a ResNet-50 using Caffe. I did some research on ResNet, and here is what I learned. 

### ResNet

Kaiming He(何恺明) is an absolute beast when it comes to computer vision and deep learning. He's won several Best Paper Award in CVPR and ICCV and developed state-of-the-art ResNet, Faster-R-CNN and Mask R-CNN. ResNet was developed when he was in Microsoft. It won the ImageNet competition, beat the humans and became a prevalent architecutre for deep learning today. It stands for Residual Learning and was designed to address the problem involved with deep neural nets, specifically degradation. 

### Random Topics Refresher

* Least Square: a type of problem for regression where we want to fit a function to the data such that the sume of squares(distance) are minimum
* Gradient Descent: the iterative method to solve a LSQ problem. Iteratively fit the function until the gradient of error becomes 0 or minimum
* Stochastic Gradient Descent: Basically uses random walks to update cost at the end of every training instance. It runs much faster on large data set
* [Single Value Decomposation](https://www.youtube.com/watch?v=P5mlg91as1c): I've originally learned this in DataVis during a lecture for Text Mining. I came upon this technique randomly today and have forgotten what it was. This video from Stanford does a good job explaining SVD. 